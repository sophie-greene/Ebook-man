{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import comFuncs\n",
    "from comFuncs import *\n",
    "import comFuncs3\n",
    "\n",
    "import string\n",
    "import rarfile\n",
    "import re\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "import resource\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "573313"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    ind=load_obj('datas/indexdB')\n",
    "except:\n",
    "    names=!find /media/some/sam/dall -type f -iname \"index*2016*\"\n",
    "    names=names+[\"/media/some/sam/dall/New ebook packs for August 2016/New ebook packs INDEX 2003-2015.txt\"]\n",
    "    lst=[list(reversed(os.path.split(f))) for f in names]\n",
    "    result = {}\n",
    "    for item in lst:\n",
    "        if not item[0] in result.keys():\n",
    "            result[item[0]]=[]  \n",
    "        result[item[0]]=result[item[0]]+ [item[1]]\n",
    "\n",
    "    ind=[]\n",
    "    for k in result.keys():\n",
    "        rd=open(result[k][0]+\"/\"+k).readlines()\n",
    "        ind=ind+ zip(rd,[result[k][0]]*len(rd),[k]*len(rd))\n",
    "    ind=[idc for idc in ind if idc[0].count('\\\\')>0]\n",
    "    save_obj(ind, 'datas/indexdB')  \n",
    "len(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removeLTdash(strg,charr):\n",
    "    if len (strg)>3:\n",
    "        strgg=strg.strip()\n",
    "        if strgg[0]==charr:\n",
    "            strgg=strgg[1:].strip()\n",
    "        if strgg[-1]==charr:\n",
    "            strgg=strgg[:-1].strip()\n",
    "        return strgg\n",
    "    return strg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractSeries(strg):\n",
    "    series=re.findall('.+-(\\s*\\[.+\\]\\s*-).+.rar',strg)\n",
    "    if len(series)>0:\n",
    "        series=removeLTdash(series[0],'-')\n",
    "        series=removeLTdash(series,'[')\n",
    "        series=removeLTdash(series,']')\n",
    "        return series\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractAuthor(strg):\n",
    "    author=re.findall('(.+?\\s*-)',strg)\n",
    "    if len(author)>0:\n",
    "        return removeLTdash(author[0],'-')\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extractAdd(title):\n",
    "    add=[]\n",
    "    if title.count(')')>0 and title.count('(')>0:\n",
    "        cnt=0\n",
    "        while min([title.count('('),title.count(')')])>0:\n",
    "        \n",
    "            add.append(re.findall('.*\\(\\s*(.+?)\\s*\\)',title)[0] .strip())\n",
    "        \n",
    "            title=title.replace(add[-1],\"\")\n",
    "            title=re.sub(' +',' ',title)\n",
    "            cnti=0\n",
    "            while title.count('()')>0:\n",
    "                title=title.replace(\"()\",\"\").strip()\n",
    "                if cnti>9:\n",
    "                    return title\n",
    "                cnti+=1\n",
    "            #print title\n",
    "            cntj=0   \n",
    "            while title.count('( )'):\n",
    "                title=title.replace(\"( )\",\"\").strip()\n",
    "                if cntj>9:\n",
    "                    return title,add\n",
    "                cntj+=1\n",
    "            if cnt>9:\n",
    "                return title,add\n",
    "            cnt+=1\n",
    "    return title,add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extractTitle(strg):\n",
    "    title=re.findall('.+(\\s*-.+)\\(.*',strg)\n",
    "    if len(title)>0:\n",
    "        title=removeLTdash(title[0],'-')\n",
    "        return title\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractExt(strg):\n",
    "    ext=re.findall('.+(\\s\\(.+\\)\\s*).rar',strg)\n",
    "    if len(ext)>0:\n",
    "        return  ''.join(c for c in ext[0] if c in string.letters+string.digits+\" \").strip()\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extractRecord(inn):\n",
    "        tmp = inn.strip().split('\\\\')\n",
    "        rar=''.join(t for t in tmp[0] if t in string.digits+\"- \")\n",
    "        rar=re.sub(' +',' ',rar)\n",
    "        if len(tmp)>1:\n",
    "            series = extractSeries(tmp[1])\n",
    "            author = extractAuthor(tmp[1])\n",
    "            title, add = extractAdd(extractTitle(tmp[1]))\n",
    "            exten = extractExt(tmp[1])\n",
    "            strg=tmp[1].replace('.rar','')\n",
    "            strg=strg.replace(author,'')\n",
    "            strg=strg.replace(title,'')\n",
    "            strg=strg.replace(series,'')\n",
    "            strg=strg.replace(exten,'')\n",
    "            for l in add:\n",
    "                strg=strg.replace(l,'')\n",
    "            rem=''.join(st for st in strg if st in string.letters+\" '\")\n",
    "            rem=' '.join(rem.split())\n",
    "            #print 'remaining: ',strg\n",
    "            #rar folder, file,extra\n",
    "            return [rar,inn,rem,author,series,title,' '.join(add),exten]\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'03-01-2016 Part 1-2\\\\A J Bromley - [Annie Parker Mystery Short] - Welcome to Sweetwater (Christmas Cookies; Spring Fling; Shopping Spree; Slim Gym; Afternoon Delight) (retail) (azw3).rar\\r\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indd=zip(*ind)[0]\n",
    "indd[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('03-01-2016 Part 1-2\\\\A J Bromley - [Annie Parker Mystery Short] - Welcome to Sweetwater (Christmas Cookies; Spring Fling; Shopping Spree; Slim Gym; Afternoon Delight) (retail) (azw3).rar\\r\\n',\n",
       " '/media/some/sam/dall/New ebook packs for March 2016',\n",
       " 'Index 2016-03.txt')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('records: ', 573313)\n",
      "('time: ', 52.696621894836426)\n",
      "('resources: ', 877)\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "try:\n",
    "    dBB=load_obj('datas/dBB')\n",
    "except:\n",
    "    \n",
    "    p = Pool(8)\n",
    "    dBB=p.map(extractRecord, indd)\n",
    "    p.terminate()\n",
    "    p.close()\n",
    "    dBB=filter(None,dBB)\n",
    "    save_obj(dBB, 'datas/dBB') \n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print('records: ',len(dBB))\n",
    "print('time: ',total)\n",
    "print('resources: ',resource.getrusage(resource.RUSAGE_SELF).ru_maxrss / 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def matchRec(rec,search):\n",
    "\n",
    "    cos=[]\n",
    "    for r in rec[2:]:\n",
    "        if len(r)>2:\n",
    "            for se in search.split(' '):\n",
    "                if len(se)>1:\n",
    "                    cc=get_cosine(text_to_vector(r.lower()),text_to_vector(se.lower()))\n",
    "                    #print r,se\n",
    "                    if cc>0.0:\n",
    "                        cos.append(cc)\n",
    "    return cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def findrec(rec,search):\n",
    "    res=matchRec(rec,search)\n",
    "    if len(res)>0:\n",
    "        score=sum(res)/len(search.split(' '))\n",
    "        #print rec,score,res\n",
    "        \n",
    "        if score>.5:\n",
    "            rt=rec+[score]+res\n",
    "            print ' '.join( rt[2:6])\n",
    "            return rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#serial\n",
    "#search=\"powerone\"\n",
    "#t0 = time.time()\n",
    "\n",
    "#for rec in dBB:\n",
    "#    findrec(rec,search)\n",
    "#t1 = time.time()\n",
    "#t1-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Powerone  Hell Hospital [MF]\n",
      "('records: ', 1)\n",
      "('time: ', 121.86885404586792)\n",
      "('resources: ', 873)\n"
     ]
    }
   ],
   "source": [
    "#parallel\n",
    "search=\"powerone hospital\"\n",
    "t0 = time.time()\n",
    "p = Pool(20)\n",
    "res=p.map(functools.partial(findrec, search=search), dBB)\n",
    "p.terminate()\n",
    "p.close()\n",
    "res=filter(None,res)\n",
    "#save_obj(res, 'datas/res') \n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print('records: ',len(res))\n",
    "print('time: ',total)\n",
    "print('resources: ',resource.getrusage(resource.RUSAGE_SELF).ru_maxrss / 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "search=\"Building Harlequins Moon Larry Niven\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allres=[list(\n",
    "        filter(\n",
    "            lambda x: any(xx.lower().replace(\"'\",\"\").count(se.strip().lower()) > 0 for xx in x[3:7]  ), dBB)) \n",
    "        for se in search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def searchdb(seTerm,db):\n",
    "    allres=[list\n",
    "            (filter\n",
    "             (lambda x: any(xx.lower().replace(\"'\",\"\").count(se.strip().lower()) > 0 for xx in x[3:7]  ), db)) \n",
    "            for se in seTerm]\n",
    "    return reduce(lambda sx, sy: filter(lambda x: x in sx,sy), ((i) for i in allres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findr(name, path):\n",
    "    #print name,path\n",
    "    res=!find $path -type f -iname $name\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def similarity(a,b):\n",
    "    return get_cosine(text_to_vector(a.lower()),text_to_vector(b.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/some/an/’: File exists\n",
      "1 -  03-13-2016 Part 2-2\\Powerone - Hell Hospital [MF] (pdf).rar powerone hell hospital [mf]\n"
     ]
    }
   ],
   "source": [
    "foo=\"/home/some/an/\"\n",
    "!mkdir \"$foo\"\n",
    "cnt=0\n",
    "sor = sorted(res, key=lambda tup: tup[7])\n",
    "#epub first\n",
    "sorr=list(filter(lambda x: x[7].lower().count('epub') > 0, sor))+list(filter(lambda x: x[7].lower().count('epub') == 0, sor))\n",
    "books=[]\n",
    "for r in sorr:\n",
    " \n",
    "        found=r[0]\n",
    "        baseName=' '.join(ss for ss in r[3:6] if len(ss)>0).lower()\n",
    "        if any(similarity(baseName,b.lower())>.75 for b in books):\n",
    "            continue\n",
    "        found=r[0].replace(\"  \",\" \").replace(\" \",\"*\").replace(\"_\",\"*\")+\"*.rar\"\n",
    "        fls=findr(found,'/media/some/sam/dall/')\n",
    "        #print found\n",
    "        if len(fls)>0:\n",
    "            for flss in fls:\n",
    "                rf = rarfile.RarFile(flss)\n",
    "                booFound=False\n",
    "                for f in rf.infolist():\n",
    "                    #print f.filename, f.file_size\n",
    "                    if similarity(f.filename,r[1])>0.99:\n",
    "                        cnt+=1\n",
    "                        booFound=True\n",
    "                        print cnt,\"- \",f.filename,baseName\n",
    "                        try:\n",
    "                            rf.extract(f,foo)\n",
    "                            books.append(baseName)\n",
    "                        except:\n",
    "                            print \"reading problem\",r[1],\"\"\n",
    "                        ft=foo+f.filename.split('\\\\')[1]\n",
    "                        fo=foo+f.filename.split('\\\\')[0]\n",
    "                        fn=fo+\"/\"+f.filename.split('\\\\')[1]\n",
    "                        os.rename(fn,ft) \n",
    "                        os.rmdir(fo)\n",
    "                if not booFound:\n",
    "                    print \"*couldnt find file\"\n",
    "                    \n",
    "    \n",
    "        else:\n",
    "            print \"couldnt find file  \",found\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4675"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr='/media/some/sam/download-ep/'\n",
    "lst=!find \"$dr\" -type f -iname \"*.epub\"\n",
    "len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def searchdb(seTerm,db):\n",
    "    seTerm=[se.strip() for se in seTerm.split(' ')]\n",
    "    allres=[list\n",
    "            (filter\n",
    "             (lambda x: any(xx.lower().replace(\"'\",\"\").count(se.strip().lower()) > 0 for xx in x[3:7]  ), db)) \n",
    "            for se in seTerm]\n",
    "    #find common items in multiple lists\n",
    "    return reduce(lambda sx, sy: filter(lambda x: x in sx,sy), ((i) for i in allres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rmlst=[]\n",
    "t0 = time.time()\n",
    "for f in lst:\n",
    "    #print 'Full Name: ',f,'\\n'\n",
    "\n",
    "    fp,fn=os.path.split(f)\n",
    "    ext=re.findall('.+(\\..+)',fn)[0]\n",
    "    fn=fn.replace('_',\" \").replace(ext,'')\n",
    "    fn=''.join(fnn for fnn in fn if fnn in string.letters+\" \")\n",
    "    #print 'File Name: ',fn,'\\n'\n",
    "    #print 'Full Folder Name: ',fp,'\\n'\n",
    "    try:\n",
    "        fpr=re.findall('.*/(.+)',fp)[0].replace('_',\" \")\n",
    "        #print 'Parent Folder Name:',fpr,'\\n'\n",
    "    except:\n",
    "        print \"error\"\n",
    "   \n",
    "\n",
    "    found=searchdb(fn,dBB)\n",
    "    if len(found)>0:\n",
    "            rmlst.append([f,found])\n",
    "\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print(\"files to delete\",len(rmlst))\n",
    "print('time: ',total)\n",
    "print('resources: ',resource.getrusage(resource.RUSAGE_SELF).ru_maxrss / 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "strg=!ebook-meta \"$f\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stdict={st.split(\"  : \")[0].strip(): st.split(\"  : \")[1].strip() for st in strg if st.count(\"  : \")>0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Larry Niven & Brenda Cooper [Niven, Larry] Building Harlequin's Moon\""
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stdict['Author(s)']+\" \"+stdict['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Harlequins Moon - Larry Niven  Brenda Cooper\n",
      "New Books 04-29-2010\\Larry Niven - Handicap (html).rar\n"
     ]
    }
   ],
   "source": [
    "ffd=stdict['Published'][:stdict['Published'].index('T')]\n",
    "yr=ffd[0:4]\n",
    "dd=ffd[-2:]\n",
    "mm=ffd[5:7]\n",
    "print fn\n",
    "fnd=\"*\"+yr+\"*.rar\"\n",
    "#print fnd\n",
    "fls=findr(fnd,'/media/some/sam/dall/')\n",
    "if fls>0:\n",
    "    for flss in fls:\n",
    "        rf = rarfile.RarFile(flss)\n",
    "        for fll in rf.infolist():\n",
    "                #print fll.filename.split('\\\\')[1],fn\n",
    "                if fll.filename.count(\"\\\\\")>0 and similarity(fll.filename.split('\\\\')[1],fn)>0.3:\n",
    "                    print fll.filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "fls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('^Published:(.+)',strg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Caught Up in Her (Caught Up In Love 0.5.epub'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

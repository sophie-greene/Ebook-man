{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import comFuncs\n",
    "from comFuncs import *\n",
    "import comFuncs3\n",
    "\n",
    "import string\n",
    "import rarfile\n",
    "import re\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "import resource\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "573313"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    ind=load_obj('datas/indexdB')\n",
    "except:\n",
    "    names=!find /media/some/sam/dall -type f -iname \"index*2016*\"\n",
    "    names=names+[\"/media/some/sam/dall/New ebook packs for August 2016/New ebook packs INDEX 2003-2015.txt\"]\n",
    "    lst=[list(reversed(os.path.split(f))) for f in names]\n",
    "    result = {}\n",
    "    for item in lst:\n",
    "        if not item[0] in result.keys():\n",
    "            result[item[0]]=[]  \n",
    "        result[item[0]]=result[item[0]]+ [item[1]]\n",
    "\n",
    "    ind=[]\n",
    "    for k in result.keys():\n",
    "        rd=open(result[k][0]+\"/\"+k).readlines()\n",
    "        ind=ind+ zip(rd,[result[k][0]]*len(rd),[k]*len(rd))\n",
    "    ind=[idc for idc in ind if idc[0].count('\\\\')>0]\n",
    "    save_obj(ind, 'datas/indexdB')  \n",
    "len(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removeLTdash(strg,charr):\n",
    "    if len (strg)>3:\n",
    "        strgg=strg.strip()\n",
    "        if strgg[0]==charr:\n",
    "            strgg=strgg[1:].strip()\n",
    "        if strgg[-1]==charr:\n",
    "            strgg=strgg[:-1].strip()\n",
    "        return strgg\n",
    "    return strg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractSeries(strg):\n",
    "    series=re.findall('.+-(\\s*\\[.+\\]\\s*-).+.rar',strg)\n",
    "    if len(series)>0:\n",
    "        series=removeLTdash(series[0],'-')\n",
    "        series=removeLTdash(series,'[')\n",
    "        series=removeLTdash(series,']')\n",
    "        return series\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractAuthor(strg):\n",
    "    author=re.findall('(.+?\\s*-)',strg)\n",
    "    if len(author)>0:\n",
    "        return removeLTdash(author[0],'-')\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extractAdd(title):\n",
    "    add=[]\n",
    "    if title.count(')')>0 and title.count('(')>0:\n",
    "        cnt=0\n",
    "        while min([title.count('('),title.count(')')])>0:\n",
    "        \n",
    "            add.append(re.findall('.*\\(\\s*(.+?)\\s*\\)',title)[0] .strip())\n",
    "        \n",
    "            title=title.replace(add[-1],\"\")\n",
    "            title=re.sub(' +',' ',title)\n",
    "            cnti=0\n",
    "            while title.count('()')>0:\n",
    "                title=title.replace(\"()\",\"\").strip()\n",
    "                if cnti>9:\n",
    "                    return title\n",
    "                cnti+=1\n",
    "            #print title\n",
    "            cntj=0   \n",
    "            while title.count('( )'):\n",
    "                title=title.replace(\"( )\",\"\").strip()\n",
    "                if cntj>9:\n",
    "                    return title,add\n",
    "                cntj+=1\n",
    "            if cnt>9:\n",
    "                return title,add\n",
    "            cnt+=1\n",
    "    return title,add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extractTitle(strg):\n",
    "    title=re.findall('.+(\\s*-.+)\\(.*',strg)\n",
    "    if len(title)>0:\n",
    "        title=removeLTdash(title[0],'-')\n",
    "        return title\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractExt(strg):\n",
    "    ext=re.findall('.+(\\s\\(.+\\)\\s*).rar',strg)\n",
    "    if len(ext)>0:\n",
    "        return  ''.join(c for c in ext[0] if c in string.letters+string.digits+\" \").strip()\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extractRecord(inn):\n",
    "        tmp = inn.strip().split('\\\\')\n",
    "        rar=''.join(t for t in tmp[0] if t in string.digits+\"- \")\n",
    "        rar=re.sub(' +',' ',rar)\n",
    "        if len(tmp)>1:\n",
    "            series = extractSeries(tmp[1])\n",
    "            author = extractAuthor(tmp[1])\n",
    "            title, add = extractAdd(extractTitle(tmp[1]))\n",
    "            exten = extractExt(tmp[1])\n",
    "            strg=tmp[1].replace('.rar','')\n",
    "            strg=strg.replace(author,'')\n",
    "            strg=strg.replace(title,'')\n",
    "            strg=strg.replace(series,'')\n",
    "            strg=strg.replace(exten,'')\n",
    "            for l in add:\n",
    "                strg=strg.replace(l,'')\n",
    "            rem=''.join(st for st in strg if st in string.letters+\" '\")\n",
    "            rem=' '.join(rem.split())\n",
    "            #print 'remaining: ',strg\n",
    "            #rar folder, file,extra\n",
    "            return [rar,inn,rem,author,series,title,' '.join(add),exten]\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'03-01-2016 Part 1-2\\\\A J Bromley - [Annie Parker Mystery Short] - Welcome to Sweetwater (Christmas Cookies; Spring Fling; Shopping Spree; Slim Gym; Afternoon Delight) (retail) (azw3).rar\\r\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indd=zip(*ind)[0]\n",
    "indd[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('03-01-2016 Part 1-2\\\\A J Bromley - [Annie Parker Mystery Short] - Welcome to Sweetwater (Christmas Cookies; Spring Fling; Shopping Spree; Slim Gym; Afternoon Delight) (retail) (azw3).rar\\r\\n',\n",
       " '/media/some/sam/dall/New ebook packs for March 2016',\n",
       " 'Index 2016-03.txt')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('records: ', 573313)\n",
      "('time: ', 32.61633110046387)\n",
      "('resources: ', 877)\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "try:\n",
    "    dBB=load_obj('datas/dBB')\n",
    "except:\n",
    "    \n",
    "    p = Pool(8)\n",
    "    dBB=p.map(extractRecord, indd)\n",
    "    p.terminate()\n",
    "    p.close()\n",
    "    dBB=filter(None,dBB)\n",
    "    save_obj(dBB, 'datas/dBB') \n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print('records: ',len(dBB))\n",
    "print('time: ',total)\n",
    "print('resources: ',resource.getrusage(resource.RUSAGE_SELF).ru_maxrss / 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def matchRec(rec,search):\n",
    "\n",
    "    cos=[]\n",
    "    for r in rec[2:]:\n",
    "        if len(r)>2:\n",
    "            for se in search.split(' '):\n",
    "                if len(se)>1:\n",
    "                    cc=get_cosine(text_to_vector(r.lower()),text_to_vector(se.lower()))\n",
    "                    #print r,se\n",
    "                    if cc>0.0:\n",
    "                        cos.append(cc)\n",
    "    return cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def findrec(rec,search):\n",
    "    res=matchRec(rec,search)\n",
    "    if len(res)>0:\n",
    "        score=sum(res)/len(search.split(' '))\n",
    "        #print rec,score,res\n",
    "        \n",
    "        if score>.5:\n",
    "            rt=rec+[score]+res\n",
    "            print ' '.join( rt[2:6])\n",
    "            return rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def searchdb(seTerm):\n",
    "    seTerm=[se.strip() for se in seTerm.split(' ')]\n",
    "    allres=[list\n",
    "            (filter\n",
    "             (lambda x: any(xx.lower().replace(\"'\",\"\").count(se.strip().lower()) > 0 for xx in x[3:7]  ), dBB)) \n",
    "            for se in seTerm]\n",
    "    #find common items in multiple lists\n",
    "    return reduce(lambda sx, sy: filter(lambda x: x in sx,sy), ((i) for i in allres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def searchindd(seTerm):\n",
    "    \n",
    "   \n",
    "    if len(seTerm)>=2 and len(seTerm)<7:\n",
    "        print \"Search Term: \",' '.join(seTerm)\n",
    "        allres=[list\n",
    "                (filter\n",
    "                 (lambda x: any(xx.lower().replace(\"'\",\"\").count(se.strip().lower()) > 0 \n",
    "                                for xx in x.replace(\"_\",\" \").replace(\"-\",\" \").split('\\\\')[1].split(\" \") ), indd)) \n",
    "                for se in seTerm]\n",
    "        #find common items in multiple lists\n",
    "        return reduce(lambda sx, sy: filter(lambda x: x in sx,sy), ((i) for i in allres))\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search term:  powerone hospital\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['03-13-2016 Part 2-2\\\\Powerone - Hell Hospital [MF] (pdf).rar\\r\\n']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search=\"powerone hospital\"\n",
    "res=searchindd(search)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findr(name, path):\n",
    "    #print name,path\n",
    "    res=!find $path -type f -iname $name\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def similarity(a,b):\n",
    "    return get_cosine(text_to_vector(a.lower()),text_to_vector(b.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "foo=\"/home/some/an/\"\n",
    "!mkdir \"$foo\"\n",
    "cnt=0\n",
    "sor = sorted(res, key=lambda tup: tup[7])\n",
    "#epub first\n",
    "sorr=list(filter(lambda x: x[7].lower().count('epub') > 0, sor))+list(filter(lambda x: x[7].lower().count('epub') == 0, sor))\n",
    "books=[]\n",
    "for r in sorr:\n",
    " \n",
    "        found=r[0]\n",
    "        baseName=' '.join(ss for ss in r[3:6] if len(ss)>0).lower()\n",
    "        if any(similarity(baseName,b.lower())>.75 for b in books):\n",
    "            continue\n",
    "        found=r[0].replace(\"  \",\" \").replace(\" \",\"*\").replace(\"_\",\"*\")+\"*.rar\"\n",
    "        fls=findr(found,'/media/some/sam/dall/')\n",
    "        #print found\n",
    "        if len(fls)>0:\n",
    "            for flss in fls:\n",
    "                rf = rarfile.RarFile(flss)\n",
    "                booFound=False\n",
    "                for f in rf.infolist():\n",
    "                    #print f.filename, f.file_size\n",
    "                    if similarity(f.filename,r[1])>0.99:\n",
    "                        cnt+=1\n",
    "                        booFound=True\n",
    "                        print cnt,\"- \",f.filename,baseName\n",
    "                        try:\n",
    "                            rf.extract(f,foo)\n",
    "                            books.append(baseName)\n",
    "                        except:\n",
    "                            print \"reading problem\",r[1],\"\"\n",
    "                        ft=foo+f.filename.split('\\\\')[1]\n",
    "                        fo=foo+f.filename.split('\\\\')[0]\n",
    "                        fn=fo+\"/\"+f.filename.split('\\\\')[1]\n",
    "                        os.rename(fn,ft) \n",
    "                        os.rmdir(fo)\n",
    "                if not booFound:\n",
    "                    print \"*couldnt find file\"\n",
    "                    \n",
    "    \n",
    "        else:\n",
    "            print \"couldnt find file  \",found\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4675"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr='/media/some/sam/download-ep/'\n",
    "try:\n",
    "    lst=load_obj(\"datas/lstepubdown\")\n",
    "except:\n",
    "    lst=!find \"$dr\" -type f -iname \"*.epub\"\n",
    "    \n",
    "    save_obj(lst,\"datas/lstepubdown\")\n",
    "len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cleanSe(seTerm):\n",
    "    cmlst=list(set([it.lower().strip() for it in open('commonLst.dat').readlines()]))\n",
    "    seTerm=''.join(fnn for fnn in seTerm if fnn in string.letters+\" \")\n",
    "    seTerm=' '.join(it.strip().lower() for it in seTerm.split(\" \") if not any(similarity(it,b.lower())>.9 for b in cmlst)) \n",
    "    seTerm=' '.join(seTerm.split())\n",
    "    return [se.strip().lower() for se in list(set(seTerm.split(' '))) if len(se)>2]\n",
    "def findFile(f):  \n",
    "    fp,fn=os.path.split(f)\n",
    "    ext=re.findall('.+(\\..+)',fn)[0]\n",
    "    fn=fn.replace('_',\" \").replace(ext,'').lower()\n",
    "    fpr=re.findall('.*/(.+)',fp)[0].replace('_',\" \").lower()\n",
    "  \n",
    "    se=cleanSe(fn)\n",
    "    found=searchindd(se)\n",
    "   \n",
    "    if len(found)>0:\n",
    "        #print found\n",
    "        return [f,' '.join(se),found]\n",
    "    else:\n",
    "        ser=fn+\" \"+fpr\n",
    "        se=cleanSe(ser)\n",
    "        found=searchindd(se) \n",
    "        if len(found)>0:\n",
    "        #print found\n",
    "            return [f,' '.join(se),found]\n",
    "        else:\n",
    "            #print 'search term: ',fpr\n",
    "            se=cleanSe(fpr)\n",
    "            found=searchindd(se) \n",
    "            if len(found)>0:\n",
    "                return [f,' '.join(se),found]\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Term:  poems phantasmagoria\n",
      "Search Term:  poems phantasmagoria caroll lewis\n",
      "Search Term:  lewis caroll\n",
      "None\n",
      "91.416041851\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "#print lst[0]\n",
    "print findFile(lst[4484])\n",
    "print time.time()-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Term:  captive john norman gor\n",
      "Search Term:  caught love her\n",
      "Search Term:  assassins robin hobb apprentice\n",
      "Search Term:  isaac catastrophes asimov\n",
      "Search Term:  bibi mike resnick\n",
      "Search Term:  stephen gods evening king\n",
      "Search Term:  bibi mike resnick\n",
      "Search Term:  start lauren blakely\n",
      "Search Term:  isaac catastrophes asimov\n",
      "Search Term:  kathryn kristine rusch assassins dagger\n",
      "Search Term:  case stephen king\n",
      "Search Term:  stephen gods evening king\n",
      "Search Term:  larry bird niven hand\n",
      "Search Term:  start lauren blakely\n",
      "Search Term:  case conscience macleod ken\n",
      "Search Term:  case stephen king\n",
      "Search Term:  orson ender gifts scott war card\n",
      "Search Term:  lauren blakely\n",
      "Search Term:  quest assassins robin hobb\n",
      "Search Term:  larry bird niven hand\n",
      "Search Term:  case conscience macleod ken\n",
      "Search Term:  cordwainer oneill smith casher planet gem\n",
      "Search Term:  beautiful jamie mcguire wedding\n",
      "Search Term:  john assassin norman gor\n",
      "Search Term:  blakes progress nelson\n",
      "Search Term:  fools death schoen lawrence\n",
      "Search Term:  stoker dracula stokers bram\n",
      "Search Term:  roberts cou one dark nora witch\n",
      "Search Term:  cordwainer oneill smith casher planet gem\n",
      "Search Term:  blind stephen willie king\n",
      "Search Term:  hotel agatha christie bertrams\n",
      "Search Term:  snicket lemony events unfortunate\n",
      "Search Term:  allred affairs alien katherine close encounters\n",
      "Search Term:  blind stephen willie king\n",
      "Search Term:  dark cousins witch one\n",
      "Search Term:  four stephen autopsy room king\n",
      "Search Term:  madeleine door wind lengle\n",
      "Search Term:  cordwainer oneill smith casher planet sand\n",
      "Search Term:  dostoyevsky fyodor demons\n",
      "Search Term:  thor blowback brad\n",
      "Search Term:  breathoffire hart liliana\n",
      "Search Term:  robert reed friend best womans\n",
      "Search Term:  four stephen autopsy room king\n",
      "Search Term:  dostoyevsky fyodor demons\n",
      "Search Term:  larry black bordered niven\n",
      "Search Term:  liliana hart\n",
      "Search Term:  rackrent castle edgeworth maria\n",
      "Search Term:  liliana hart\n",
      "Search Term:  sector james general diagnosis white final\n",
      "Search Term:  sarah garden zettel young swordswomans primer\n",
      "Search Term:  mcdonald colossal lawrence failure common sense\n",
      "Search Term:  larry black bordered niven\n",
      "Search Term:  mackenzie dane bros\n",
      "Search Term:  rackrent castle edgeworth maria\n",
      "Search Term:  liliana mackenzie hart dane bros\n",
      "Search Term:  bourne robert trilogy identity ludlum\n",
      "Search Term:  waldrop gods howard hooks\n",
      "Search Term:  richmond anthony castle trollope\n",
      "Search Term:  lewis babbitt sinclair\n",
      "Search Term:  mcdonald colossal lawrence failure common sense\n",
      "Search Term:  liliana hart\n",
      "Search Term:  lewis babbitt sinclair\n",
      "Search Term:  thompson hells hunter angel\n",
      "Search Term:  richmond anthony castle trollope\n",
      "Search Term:  bourne robert trilogy identity ludlum\n",
      "Search Term:  mackenzie thomas bros\n",
      "Search Term:  star babel samuel delany empire\n",
      "Search Term:  shaw craig dwarves gardner difficulty with\n",
      "Search Term:  king emperor harrison harry\n",
      "Search Term:  memoirs burney heiress fanny cecilia\n",
      "Search Term:  liliana mackenzie hart thomas bros\n",
      "Search Term:  supremacy bourne robert trilogy ludlum\n",
      "Search Term:  star babel samuel delany empire\n",
      "Search Term:  king emperor harrison harry\n",
      "Search Term:  shaw craig dwarves gardner difficulty with\n",
      "Search Term:  memoirs burney heiress fanny cecilia\n",
      "Search Term:  liliana hart\n",
      "Search Term:  supremacy bourne robert trilogy ludlum\n",
      "Search Term:  mackenzie riley bros\n",
      "Search Term:  bridge blish james\n",
      "Search Term:  privateers anderson barretts gentry\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t0 = time.time()\n",
    "p = Pool(6)\n",
    "rmlst=p.map(findFile, lst[:500])\n",
    "p.terminate()\n",
    "p.close()\n",
    "rmlst=filter(None,rmlst)\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print(\"files to delete\",len(rmlst))\n",
    "print('time: ',total)\n",
    "print('resources: ',resource.getrusage(resource.RUSAGE_SELF).ru_maxrss / 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('/media/some/sam/download-ep/Calibre Ebook Group Flood - Warhammer - 428 Books/Sarah Cawkwell/Bitter End (202)/Bitter End - Sarah Cawkwell.epub', '/media/some/sam/download-ep/Calibre Ebook Group Flood - Warhammer - 428 Books/Sarah Cawkwell/Cause & Effect (203)/Cause & Effect - Sarah Cawkwell.epub') ('sarah end - cawkwell (202) bitter', 'sarah & (203) - effect cawkwell cause')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4673"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fls=zip(*rmlst)[0]\n",
    "print fls,zip(*rmlst)[1]\n",
    "#print zip(*rmlst)[1]\n",
    "lst=filter(lambda x: x not in fls,lst)\n",
    "len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/some/repo\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for f in fls:\n",
    "    if os.path.exists(f):\n",
    "        os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/media/some/sam/download-ep/Calibre Ebook Group Flood - Warhammer - 428 Books/Sarah Cawkwell/Bitter End (202)/Bitter End - Sarah Cawkwell.epub',\n",
       " '/media/some/sam/download-ep/Calibre Ebook Group Flood - Warhammer - 428 Books/Sarah Cawkwell/Cause & Effect (203)/Cause & Effect - Sarah Cawkwell.epub')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values are [ 0.42667517  0.08130225  0.18769461  0.62685297  0.91800376  0.72639408\n",
      "  0.04488596  0.06138383  0.53230967  0.94864732  0.95114921  0.51271149\n",
      "  0.50810097  0.04019267  0.71379624  0.42901035  0.74664958  0.58132285\n",
      "  0.47031118  0.97987564]\n",
      "values are [ 0.          0.08130225  0.18769461  0.62685297  0.91800376  0.\n",
      "  0.04488596  0.06138383  0.53230967  0.94864732  0.          0.51271149\n",
      "  0.50810097  0.04019267  0.71379624  0.          0.74664958  0.58132285\n",
      "  0.47031118  0.97987564]\n",
      "type is <type 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process\n",
    "import sharedmem\n",
    "import numpy\n",
    "\n",
    "def do_work(data, start):\n",
    "    data[start] = 0;\n",
    "\n",
    "def split_work(num):\n",
    "    n = 20\n",
    "    width  = n/num\n",
    "    shared = sharedmem.empty(n)\n",
    "    shared[:] = numpy.random.rand(1, n)[0]\n",
    "    print \"values are %s\" % shared\n",
    "\n",
    "    processes = [Process(target=do_work, args=(shared, i*width)) for i in xrange(num)]\n",
    "    for p in processes:\n",
    "        p.start()\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "\n",
    "    print \"values are %s\" % shared\n",
    "    print \"type is %s\" % type(shared[0])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    split_work(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

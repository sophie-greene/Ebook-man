{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from ebooklib import epub \n",
    "from  comFunc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''d_dir = '/media/sf_lbuntu/calibre/'\n",
    "files = find('*.epub', d_dir)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''for f in files:\n",
    "    ft=f[:-4]+\"txt\"\n",
    "    !ebook-convert \"$f\" \"$ft\" >/dev/null\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5507"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f=open('keywords.txt')\n",
    "keywords=list(s.replace('\\n','') for s in f.readlines())\n",
    "f.close()\n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5567"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "d_dir = '/media/sf_lbuntu/calibre/'\n",
    "txtfiles = find('*.txt', d_dir)\n",
    "len(txtfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "shuffle(txtfiles)\n",
    "try:\n",
    "    booksTags=load_obj('booksTags')\n",
    "except:\n",
    "    booksTags={}\n",
    "    save_obj(booksTags, 'booksTags')\n",
    "cnt=0\n",
    "for f in reversed(txtfiles):\n",
    "    name=f.split('/')[-1][:-4]\n",
    "    if name not in booksTags.keys():\n",
    "        fl= open(f,'r')\n",
    "        txt=fl.read().lower()\n",
    "        hist=nltk.FreqDist(txt.split())\n",
    "        res=[[l,hist[l.strip()]] for l in keywords if l.strip() in hist.keys() ]\n",
    "        tag=', '.join(r[0].strip() for r in res if r[1]>0)\n",
    "        ff=f[:-3]+\"epub\" \n",
    "        \n",
    "        if len(tag)>0 :\n",
    "            path=f.replace(f.split(os.sep)[-1],'')\n",
    "            fm=path+\"metadata.opf\"\n",
    "            !ebook-meta \"$ff\" --tag \"$tag\" > /dev/null\n",
    "            !ebook-meta \"$ff\" --to-opf \"$fm\" >/dev/null\n",
    "            booksTags[name]=' '.join(r[0]+\": \"+ str(r[1]) for r in res)\n",
    "            print (cnt,f.split('/')[-1][:-4],res)\n",
    "        cnt+=1\n",
    "        if cnt % 70 == 0:\n",
    "            tmp=booksTags.copy()\n",
    "            tmp.update(load_obj('booksTags'))\n",
    "            booksTags=tmp\n",
    "            save_obj(booksTags, 'booksTags')\n",
    "            #break\n",
    "tmp=booksTags.copy()\n",
    "tmp.update(load_obj('booksTags'))\n",
    "booksTags=tmp\n",
    "save_obj(booksTags, 'booksTags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ff=f[:-3]+\"epub\"\n",
    "#!ebook-meta \"$ff\"\n",
    "ff=txtfiles[-2][:-3]+\"epub\"\n",
    "meta=!ebook-meta \"$ff\" | grep 'Tags'\n",
    "meta[0].split(':')[1]\n",
    "#tag='rich, protect,love'\n",
    "#!ebook-meta \"$ff\" --tag \"$tag\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keywords=['millionaire','billionaire','rich','stalker','protect']\n",
    "f= open('output.txt','r')\n",
    "txt=f.read()\n",
    "hist=nltk.FreqDist(txt.split())\n",
    "res=[[l,hist[l]] for l in keywords if l in hist.keys() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "meta=!ebook-meta \"$f\" | grep 'Title'\n",
    "meta[0].split(':')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "nop='\\t\\n\\r\\x0b\\x0c'\n",
    "def stripnp(s):\n",
    "    return ''.join(x for x in s if x in string.printable[:-5]+string.printable[-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s=(html2txt((lst[-5][1])))\n",
    "txt=stripnp(s)\n",
    "txt=\" \".join(txt.replace('\\n',' ').split()) \n",
    "dict=list(nltk.FreqDist(txt.split()).keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keyword_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import RAKE \n",
    "stop = RAKE.RAKE.load_stop_words('SmartStoplist.txt')\n",
    "rake_obj=RAKE.RAKE.Rake('SmartStoplist.txt')\n",
    "#rake_obj.run('find the key ro m billionaire')\n",
    "\n",
    "word_lst=RAKE.RAKE.separate_words(txt,6)\n",
    "keyword_candidates = RAKE.RAKE.generate_candidate_keywords(word_lst,\"^.+ing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "def stripnp(s):\n",
    "    return ''.join(x for x in s if x in string.printable[:-5]+string.printable[-4])\n",
    "def html2txt(html):\n",
    "    #print (html[:40])\n",
    "    soup = BeautifulSoup(html,\"lxml\")\n",
    "    s=soup.get_text()\n",
    "    txt=stripnp(s)\n",
    "    return\" \".join(txt.replace('\\n',' ').split()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "book=epub.read_epub(files[100])\n",
    "lst=[]\n",
    "for b in book.get_items_of_type(9):\n",
    "    lst.append (b.get_content())\n",
    "s=' '.join(html2txt(l) for l in lst)\n",
    "txt=stripnp(s)\n",
    "txt=\" \".join(txt.replace('\\n',' ').split()) \n",
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ch_loc=txt.lower().find('chapter')\n",
    "ch_loc,len(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "txt=txt[ch_loc:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! echo 'bleed\\n' >> keywords.txt\n",
    "#!cat keywords.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ff.replace(ff.split(os.sep)[-1],'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from ebooklib import epub \n",
    "from  comFunc import *\n",
    "\n",
    "d_dir = '/media/sf_lbuntu/calibre/'\n",
    "txtfiles = find('*.txt', d_dir)\n",
    "\n",
    "print (len(txtfiles))\n",
    "\n",
    "\n",
    "f=open('keywords.txt')\n",
    "keywords=list(s.replace('\\n','') for s in f.readlines())\n",
    "f.close()\n",
    "\n",
    "try:\n",
    "    booksTags=load_obj('booksTags')\n",
    "except:\n",
    "    booksTags={}\n",
    "    save_obj(booksTags, 'booksTags')\n",
    "\n",
    "cnt=0\n",
    "for f in reversed(txtfiles):\n",
    "    fl= open(f,'r')\n",
    "    txt=fl.read().lower()\n",
    "    fl.close()\n",
    "    hist=nltk.FreqDist(txt.split())\n",
    "    res=[[l,hist[l.strip()]] for l in keywords if l.strip() in hist.keys() ]\n",
    "    tag=', '.join(r[0].strip() for r in res if r[1]>0)\n",
    "    ff=f[:-3]+\"epub\" \n",
    "    name=f.split('/')[-1][:-4]\n",
    "    if len(tag)>0 and name not in booksTags.keys():\n",
    "        path=f.replace(f.split(os.sep)[-1],'')\n",
    "        fm=path+\"metadata.opf\"\n",
    "        get_ipython().system('ebook-meta \"$ff\" --tag \"$tag\" > /dev/null')\n",
    "        get_ipython().system('ebook-meta \"$ff\" --to-opf \"$fm\" >/dev/null')\n",
    "        booksTags[name]=' '.join(r[0]+\": \"+ str(r[1]) for r in res)\n",
    "    print (f.split('/')[-1][:-4],res,tag)\n",
    "    cnt+=1\n",
    "    if cnt % 201 == 0:\n",
    "        save_obj(booksTags, 'booksTags')\n",
    "            \n",
    "save_obj(booksTags, 'booksTags')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

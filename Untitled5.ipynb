{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "mysock.connect(('data.pr4e.org', 80))\n",
    "mysock.send('GET http://data.pr4e.org/intro-short.txt HTTP/1.0\\n\\n')\n",
    "\n",
    "while True:\n",
    "    data = mysock.recv(512)\n",
    "    if ( len(data) < 1 ) :\n",
    "        break\n",
    "    print data;\n",
    "\n",
    "mysock.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Note - this code must run in Python 2.x and you must download\n",
    "# http://www.pythonlearn.com/code/BeautifulSoup.py\n",
    "# Into the same folder as this program\n",
    "\n",
    "import urllib\n",
    "from BeautifulSoup import *\n",
    "\n",
    "url = 'http://py4inf.com/code'\n",
    "html = urllib.urlopen(url).read()\n",
    "\n",
    "soup = BeautifulSoup(html)\n",
    "\n",
    "# Retrieve all of the anchor tags\n",
    "tags = soup('a')\n",
    "for tag in tags:\n",
    "    # Look at the parts of a tag\n",
    "    print 'TAG:',tag\n",
    "    print 'URL:',tag.get('href', None)\n",
    "    print 'Contents:',tag.contents[0]\n",
    "    print 'Attrs:',tag.attrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Note - this code must run in Python 2.x and you must download\n",
    "# http://www.pythonlearn.com/code/BeautifulSoup.py\n",
    "# Into the same folder as this program\n",
    "\n",
    "import urllib\n",
    "from BeautifulSoup import *\n",
    "\n",
    "todo = list()\n",
    "visited = list()\n",
    "url = 'http://www.bbc.com'\n",
    "todo.append(url)\n",
    "\n",
    "while len(todo) > 0 :\n",
    "    print \"====== Todo list count is \",len(todo)\n",
    "    url = todo.pop()\n",
    "\n",
    "    if ( not url.startswith('http') ) : \n",
    "        print \"Skipping\", url\n",
    "        continue\n",
    "\n",
    "    if ( url.find('facebook') > 0 ) :\n",
    "        continue\n",
    "\n",
    "    if ( url in visited ) :\n",
    "        print \"Visited\", url\n",
    "        continue\n",
    "\n",
    "    print \"===== Retrieving \", url\n",
    "\n",
    "    html = urllib.urlopen(url).read()\n",
    "    soup = BeautifulSoup(html)\n",
    "    visited.append(url)\n",
    "\n",
    "    # Retrieve all of the anchor tags\n",
    "    tags = soup('a')\n",
    "    for tag in tags:\n",
    "        newurl = tag.get('href', None)\n",
    "        if ( newurl != None ) : \n",
    "            todo.append(newurl)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum =  2466\n"
     ]
    }
   ],
   "source": [
    "# Note - this code must run in Python 2.x and you must download\n",
    "# http://www.pythonlearn.com/code/BeautifulSoup.py\n",
    "# Into the same folder as this program\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum =  2466\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "from BeautifulSoup import *\n",
    "\n",
    "url = 'http://python-data.dr-chuck.net/comments_325797.html'\n",
    "print 'Sum = ',sum([int(t.contents[0]) for t in BeautifulSoup(urllib.urlopen(url).read())('span')])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter - position : 18\n",
      "Enter - count: 7\n",
      "Enter url- http://python-data.dr-chuck.net/known_by_Carragh.html\n",
      "Sequence of names:  Carragh  Tre  Jaya  Elyse  Marius  Keatin  Asya  Marcelina\n",
      "Last name in sequence:  Marcelina\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import re\n",
    "from BeautifulSoup import *\n",
    "pos = int(raw_input('Enter - position : '))\n",
    "count = int(raw_input('Enter - count: '))\n",
    "url = raw_input('Enter url- ')\n",
    "seq = [re.findall('known_by_(.+).html',url)[0]]\n",
    "for c in range(count):\n",
    "    \n",
    "    urls = [str(tag.get('href',None)) for tag in BeautifulSoup(urllib.urlopen(url).read())('a')]\n",
    "    url = urls[pos-1]\n",
    "    seq.append(\" \"+re.findall('known_by_(.+).html',url)[0])\n",
    "print \"Sequence of names: \",' '.join(seq)\n",
    "print \"Last name in sequence:\", seq[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
